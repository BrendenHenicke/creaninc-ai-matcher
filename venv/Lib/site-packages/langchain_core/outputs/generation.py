"""Generation output schema."""

from __future__ import annotations

<<<<<<< HEAD
from typing import Any, Literal, Optional

from pydantic import computed_field
=======
from typing import Any, Literal
>>>>>>> 10771d2d (Initial commit for Crean AI Matcher full app)

from langchain_core.load import Serializable
from langchain_core.utils._merge import merge_dicts


class Generation(Serializable):
    """A single text generation output.

<<<<<<< HEAD
    Generation represents the response from an "old-fashioned" LLM that
=======
    Generation represents the response from an
    `"old-fashioned" LLM <https://python.langchain.com/docs/concepts/text_llms/>__` that
>>>>>>> 10771d2d (Initial commit for Crean AI Matcher full app)
    generates regular text (not chat messages).

    This model is used internally by chat model and will eventually
    be mapped to a more general `LLMResult` object, and then projected into
    an `AIMessage` object.

    LangChain users working with chat models will usually access information via
    `AIMessage` (returned from runnable interfaces) or `LLMResult` (available
    via callbacks). Please refer the `AIMessage` and `LLMResult` schema documentation
    for more information.
    """

<<<<<<< HEAD
    def __init__(
        self,
        text: str = "",
        generation_info: Optional[dict[str, Any]] = None,
        **kwargs: Any,
    ):
        """Initialize a Generation."""
        super().__init__(generation_info=generation_info, **kwargs)
        self._text = text

    # workaround for ChatGeneration so that we can use a computed field to populate
    # the text field from the message content (parent class needs to have a property)
    @computed_field  # type: ignore[prop-decorator]
    @property
    def text(self) -> str:
        """The text contents of the output."""
        return self._text

    generation_info: Optional[dict[str, Any]] = None
=======
    text: str
    """Generated text output."""

    generation_info: dict[str, Any] | None = None
>>>>>>> 10771d2d (Initial commit for Crean AI Matcher full app)
    """Raw response from the provider.

    May include things like the reason for finishing or token log probabilities.
    """
<<<<<<< HEAD

=======
>>>>>>> 10771d2d (Initial commit for Crean AI Matcher full app)
    type: Literal["Generation"] = "Generation"
    """Type is used exclusively for serialization purposes.
    Set to "Generation" for this class."""

    @classmethod
    def is_lc_serializable(cls) -> bool:
<<<<<<< HEAD
        """Return whether this class is serializable."""
=======
        """Return True as this class is serializable."""
>>>>>>> 10771d2d (Initial commit for Crean AI Matcher full app)
        return True

    @classmethod
    def get_lc_namespace(cls) -> list[str]:
<<<<<<< HEAD
        """Get the namespace of the langchain object.

        Default namespace is ["langchain", "schema", "output"].
=======
        """Get the namespace of the LangChain object.

        Returns:
            `["langchain", "schema", "output"]`
>>>>>>> 10771d2d (Initial commit for Crean AI Matcher full app)
        """
        return ["langchain", "schema", "output"]


class GenerationChunk(Generation):
    """Generation chunk, which can be concatenated with other Generation chunks."""

<<<<<<< HEAD
    def __init__(
        self,
        text: str = "",
        generation_info: Optional[dict[str, Any]] = None,
        **kwargs: Any,
    ):
        """Initialize a GenerationChunk."""
        super().__init__(text=text, generation_info=generation_info, **kwargs)
        self._text = text

    def __add__(self, other: GenerationChunk) -> GenerationChunk:
        """Concatenate two GenerationChunks."""
=======
    def __add__(self, other: GenerationChunk) -> GenerationChunk:
        """Concatenate two `GenerationChunk`s.

        Args:
            other: Another `GenerationChunk` to concatenate with.

        Raises:
            TypeError: If other is not a `GenerationChunk`.

        Returns:
            A new `GenerationChunk` concatenated from self and other.
        """
>>>>>>> 10771d2d (Initial commit for Crean AI Matcher full app)
        if isinstance(other, GenerationChunk):
            generation_info = merge_dicts(
                self.generation_info or {},
                other.generation_info or {},
            )
            return GenerationChunk(
                text=self.text + other.text,
                generation_info=generation_info or None,
            )
        msg = f"unsupported operand type(s) for +: '{type(self)}' and '{type(other)}'"
        raise TypeError(msg)
